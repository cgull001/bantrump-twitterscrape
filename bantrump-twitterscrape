import twitter
import sys,json,csv

def twitter_search(twitter_api, q, max_results=200):

    search_results = twitter_api.search.tweets(q=q, count=100)
    # to print my search_results
    print json.dumps(search_results['search_metadata'], indent=1)
    statuses = search_results['statuses']
    max_results = min(2000, max_results)
    for _ in range(10): # 10*100 = 1000
        try:
            next_results = search_results['search_metadata']['next_results']
        except KeyError, e: # I left this so it knows no more results when next_results doesn't exist
            break
        # Create a dictionary from next_results, which has the following form:
        # ?max_id=313519052523986943&q=NCAA&include_entities=1
        kwargs = dict([ kv.split('=') for kv in next_results[1:].split("&") ])
        search_results = twitter_api.search.tweets(**kwargs)
        statuses += search_results['statuses']
        if len(statuses) > max_results:
            break
    return statuses

''' helper functions, clean data, unpack dictionaries '''
# these helper functions will help my data come through more organised so I have to do less cleaning later
def getVal(val):
    clean = ""
    if isinstance(val, bool):
        return val
    if isinstance(val, int):
        return val
    if val:
        clean = val.encode('utf-8') 
    return clean

def getLng(val):
    if isinstance(val, dict):
        return val['coordinates'][0]

def getLat(val):
    if isinstance(val, dict):
        return val['coordinates'][1]

def getPlace(val):
    if isinstance(val, dict):
        return val['full_name'].encode('utf-8')

# == OAuth Authentication ==
# These keys are needed from my twitter account in order to run the scrape
consumer_key="oHVZYKo9DCUgpMn62hfag5KKA"
consumer_secret="4kIznLGDh7i7iJkG7QgZiLTUEYRajxwYHrmCCuZv7eYGikFvvp"

access_token="362068787-Cwno0cjT7JTeiUM3nHgc8yzEqVEMql3crPpD4Ftb"
access_token_secret="n8kgtP17ohPuDk4gjnNsicS6Qg8OQlW2KAOjHl3IsRaTC"
auth = twitter.oauth.OAuth(access_token, 
  access_token_secret,
  consumer_key, 
  consumer_secret)
twitter_api = twitter.Twitter(auth=auth)
twitter_api.retry = True

q = "BanTrump"
results = twitter_search(twitter_api, q, max_results=2000)
print len(results)
# This is where I specify the hashtag BanTrump and also designate where I want the json objects sent to
# In this case I have used the code to write them to a csv file with row structures below

csvfile = open(q + '_with_profiles.csv', 'w')
csvwriter = csv.writer(csvfile)
csvwriter.writerow(['created_at',
                    'user-screen_name',
                    'text',
                    'coordinates lng',
                    'coordinates lat',
                    'place',
                    'user-location',
                    'user-geo_enabled',
                    'user-lang',
                    'user-time_zone',
                    'user-statuses_count',
                    'user-followers_count',
                    'user-created_at'])
for tweet in results:
    csvwriter.writerow([tweet['created_at'],
                            getVal(tweet['user']['screen_name']),
                            getVal(tweet['text']),
                            getLng(tweet['coordinates']),
                            getLat(tweet['coordinates']),
                            getPlace(tweet['place']),
                            getVal(tweet['user']['location']),
                            getVal(tweet['user']['geo_enabled']),
                            getVal(tweet['user']['lang']),
                            getVal(tweet['user']['time_zone']),
                            getVal(tweet['user']['statuses_count']),
                            getVal(tweet['user']['followers_count']),
                            getVal(tweet['user']['created_at'])
                            ])
print "done"
# this is so I can see the code has run and is finished
